{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from textblob import TextBlob\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_directory = '/Users/zahra/git/loris_ai_data_challenge/data/'\n",
    "\n",
    "topic_dict = {'1': 'Ordinary Life', '2': 'School Life', '3': 'Culture_Education',\n",
    "              '4': 'Attitude_Emotion', '5': 'Relationship', '6': 'Tourism' , '7': 'Health', \n",
    "              '8': 'Work', '9': 'Politics', '10': 'Finance'}\n",
    "\n",
    "action_dict = {'1': 'inform', '2': 'question', '3': 'directive', '4': 'commissive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_topic(topic):\n",
    "    return topic_dict[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_action(act):\n",
    "    return action_dict[act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r',encoding='UTF-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_conversations(category='train'):\n",
    "    \n",
    "    conversations_text = 'dialogues_' + category + '.txt'\n",
    "    conversations_emotion = 'dialogues_emotion_' + category + '.txt'\n",
    "    conversations_action = 'dialogues_act_' + category + '.txt'\n",
    "        \n",
    "    dial_dir = os.path.join(input_directory+category, conversations_text)\n",
    "    emo_dir = os.path.join(input_directory+category, conversations_emotion)\n",
    "    act_dir = os.path.join(input_directory+category, conversations_action)\n",
    "    \n",
    "    # Open files\n",
    "    in_dial = open(dial_dir, 'r')\n",
    "    in_emo = open(emo_dir, 'r')\n",
    "    in_act = open(act_dir, 'r')\n",
    "    \n",
    "    # build a list of dictionaries: a dictionary per dialogue\n",
    "    conversations_list = [\n",
    "        {\n",
    "            'utterances': utterances,\n",
    "            'emotions': emotions,\n",
    "            'actions': actions\n",
    "        }\n",
    "        for utterances, emotions, actions in (\n",
    "            (dialogue.split('__eou__')[:-1], \n",
    "             emotion.split(), \n",
    "             action.split())\n",
    "            for dialogue, emotion, action in zip(in_dial, in_emo, in_act)\n",
    "        )\n",
    "        if len(utterances) == len(emotions) == len(actions)\n",
    "    ]\n",
    "            \n",
    "    return conversations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_sentiment(conversation_dict):\n",
    "    \n",
    "    conversation_text = conversation_dict['utterances']\n",
    "    conversation_emotion_blob = []\n",
    "    \n",
    "    for sentence in conversation_text:\n",
    "        blob = TextBlob(sentence)\n",
    "        conversation_emotion_blob.append(blob.sentiment.polarity)\n",
    "    conversation_dict['blob_emotions'] = conversation_emotion_blob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_sentiments_for_all(conversations_list):\n",
    "    \n",
    "    for conversation_dict in conversations_list:\n",
    "        find_sentiment(conversation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_samples(conversations_list):\n",
    "    \n",
    "    samples_list = []\n",
    "    for conversaton_dict in conversations_list:\n",
    "        for index, utterance in enumerate(conversaton_dict['utterances']):\n",
    "            if index == 0: continue\n",
    "                \n",
    "            prev_emotion = conversaton_dict['blob_emotions'][index-1]\n",
    "            change_in_emotion = conversaton_dict['blob_emotions'][index] - prev_emotion\n",
    "            \n",
    "            samples_list.append({'utterance': utterance, 'prev_emotion': prev_emotion, \n",
    "                                'change_in_emotion': change_in_emotion})\n",
    "            \n",
    "    return samples_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \n",
    "    sentence = re.sub(r'[^\\w\\s]', ' ', sentence.strip())  \n",
    "    words = [i.lower() for i in sentence.strip().split()]\n",
    "    avg = np.zeros((50,))\n",
    "    \n",
    "    if len(words) == 0: \n",
    "        print(sentence)\n",
    "        return None\n",
    "    \n",
    "    for w in words:\n",
    "        vec = word_to_vec_map[w] if w in word_to_vec_map else word_to_vec_map['unk'] \n",
    "        avg += vec\n",
    "    avg = avg / len(words)\n",
    "        \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_svm_model(x_train, y_train):\n",
    "    # train svm\n",
    "    \n",
    "    clf = svm.SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(samples_list):\n",
    "    \n",
    "    x, y = [], []\n",
    "    for sample in samples_list:\n",
    "        vec = sentence_to_avg(sample['utterance'], word_to_vec_map)\n",
    "        if vec is None: continue\n",
    "        x.append(vec)\n",
    "        y.append(sample['change_in_emotion'])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_eval_metrics(model, x, y):\n",
    "    # calculate evaluation metrics\n",
    "    \n",
    "    score = model.score(x, y)\n",
    "    predictions = model.predict(x)\n",
    "    class_report = classification_report(y, predictions)\n",
    "    print('Error: {0} \\n'.format(score))    \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_conversations = load_conversations(category='train')\n",
    "find_sentiments_for_all(train_conversations)\n",
    "\n",
    "test_conversations = load_conversations(category='test')\n",
    "find_sentiments_for_all(test_conversations)\n",
    "\n",
    "validation_conversations = load_conversations(category='validation')\n",
    "find_sentiments_for_all(validation_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n"
     ]
    }
   ],
   "source": [
    "train_samples = create_samples(train_conversations)\n",
    "x_train, y_train = create_features(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76051 76051\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_svm_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
