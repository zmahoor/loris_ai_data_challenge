{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = '/Users/zahra/git/loris_ai_data_challenge/data/'\n",
    "\n",
    "topic_dict = {'1': 'Ordinary Life', '2': 'School Life', '3': 'Culture_Education',\n",
    "              '4': 'Attitude_Emotion', '5': 'Relationship', '6': 'Tourism' , '7': 'Health', \n",
    "              '8': 'Work', '9': 'Politics', '10': 'Finance'}\n",
    "\n",
    "action_dict = {'1': 'inform', '2': 'question', '3': 'directive', '4': 'commissive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    \n",
    "    with open(glove_file, 'r',encoding='UTF-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        \n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        \n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "            \n",
    "    return words_to_index, index_to_words, word_to_vec_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_topic(topic):\n",
    "    return topic_dict[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_action(act):\n",
    "    return action_dict[act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversations(category='train'):\n",
    "    \n",
    "    conversations_text = 'dialogues_' + category + '.txt'\n",
    "    conversations_emotion = 'dialogues_emotion_' + category + '.txt'\n",
    "    conversations_action = 'dialogues_act_' + category + '.txt'\n",
    "        \n",
    "    dial_dir = os.path.join(input_directory+category, conversations_text)\n",
    "    emo_dir = os.path.join(input_directory+category, conversations_emotion)\n",
    "    act_dir = os.path.join(input_directory+category, conversations_action)\n",
    "    \n",
    "    # Open files\n",
    "    in_dial = open(dial_dir, 'r')\n",
    "    in_emo = open(emo_dir, 'r')\n",
    "    in_act = open(act_dir, 'r')\n",
    "    \n",
    "    # build a list of dictionaries: a dictionary per dialogue\n",
    "    conversations_list = [\n",
    "        {\n",
    "            'utterances': utterances,\n",
    "            'emotions': emotions,\n",
    "            'actions': actions\n",
    "        }\n",
    "        for utterances, emotions, actions in (\n",
    "            (dialogue.split('__eou__')[:-1], \n",
    "             emotion.split(), \n",
    "             action.split())\n",
    "            for dialogue, emotion, action in zip(in_dial, in_emo, in_act)\n",
    "        )\n",
    "        if len(utterances) == len(emotions) == len(actions)\n",
    "    ]\n",
    "            \n",
    "    return conversations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiments(conversations_list):\n",
    "    \n",
    "    for conversation_dict in conversations_list:\n",
    "        \n",
    "        conversation_text = conversation_dict['utterances']\n",
    "        conversation_emotion_blob = []\n",
    "\n",
    "        for sentence in conversation_text:\n",
    "            blob = TextBlob(sentence)\n",
    "            conversation_emotion_blob.append(blob.sentiment.polarity)\n",
    "        conversation_dict['blob_emotions'] = conversation_emotion_blob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(conversations_list):\n",
    "    \n",
    "    samples_list = []\n",
    "    \n",
    "    for conversaton_dict in conversations_list:\n",
    "                    \n",
    "        for index, utterance in enumerate(conversaton_dict['utterances']):\n",
    "            if index == 0: \n",
    "                continue\n",
    "                \n",
    "            change_in_emotion = conversaton_dict['blob_emotions'][index] - conversaton_dict['blob_emotions'][index-1]\n",
    "            samples_list.append({'utterance': utterance, \n",
    "                                 'prev_emotion': conversaton_dict['blob_emotions'][index-1], \n",
    "                                 'current_emotion': conversaton_dict['blob_emotions'][index]\n",
    "                                 })          \n",
    "    return samples_list\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
